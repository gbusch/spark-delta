{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87750c01-c7ac-46c5-9611-6bbaed0674fe",
   "metadata": {},
   "source": [
    "# Append table with deletion and vacuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee210fbd-3a52-4dd4-96ae-c6c9a0a01973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.spark import get_spark\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from delta import DeltaTable\n",
    "\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4748a-99be-4e12-8205-3204f79a54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = get_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea0d05-ae27-49a4-a1cd-0e4e6a8f105e",
   "metadata": {},
   "source": [
    "## Create some mock data\n",
    "\n",
    "In this tutorial we will assume that we get data in form of snapshots that provide us with the state of some operations.\n",
    "The data might be retrieved actively by scraping it from a server but we could also imagine a streaming solution.\n",
    "\n",
    "In this usecase, we are not only interested in the most recent state but also the history of the states. This means unlike the previous tutorial we would not want to overwrite the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79335b-1511-4967-9d45-ed6e34ca7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    return spark.createDataFrame([\n",
    "            {\"operation\": 1, \"state\": randint(0, 5)},\n",
    "            {\"operation\": 2, \"state\": randint(0, 5)},\n",
    "            {\"operation\": 3, \"state\": randint(0, 5)},\n",
    "            {\"operation\": 4, \"state\": randint(0, 5)},\n",
    "        ]).withColumn(\"timestamp\", F.lit(datetime.utcnow().isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfec82f-0844-428b-ae12-823af9cfc80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_data()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c383ee9-49af-4e10-bd31-acbe8df33b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3848e3ad-8362-44e9-a1b7-ae00a6f89949",
   "metadata": {},
   "source": [
    "## Write into Delta Table\n",
    "\n",
    "We will append this data into a delta table. Delta will enforce a schema, meaning if the schema differs between appends, an error will be raised.\n",
    "Here we also partition by operation for demonstration purposes. This might make sense especially if we often filter for operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2c165-3634-4254-96ac-65a6443651ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /data/operation-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbf4c3-7fed-43bb-9431-95471da9a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode(\"append\").partitionBy(\"operation\").save(\"/data/operation-history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b80b2-1bee-40be-b56e-a09bf96db4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/operation-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62be82-b08d-42a3-be52-69a879b13692",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"/data/operation-history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec357e-8b3d-451e-98b3-1305343b1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad4343-7b48-4260-ae42-02a9b445a4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93a3ee88-3c50-4b22-9f2c-7f3ae8bff374",
   "metadata": {},
   "source": [
    "Now we will append a bit more data with a loop. Since it is a delta table we can inspect the history as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089442f1-a8e7-44ba-97fd-9f70247a37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    df = create_data()\n",
    "    df.write.format(\"delta\").mode(\"append\").partitionBy(\"operation\").save(\"/data/operation-history\")\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc16433-b969-49f8-9567-704e25528b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.history().orderBy(\"version\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d47fc7-9c73-485c-ae4f-b3078aa3ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "914e2825-f028-479a-85cc-696348596789",
   "metadata": {},
   "source": [
    "## Visualize the state history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cecc9-14da-4d25-8500-a42c38844cf3",
   "metadata": {},
   "source": [
    "Let's now read this table and make a line plot in pandas to visualize the state history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a7f28-6086-4795-b181-c8ba3cb1b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(\"/data/operation-history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809674d5-d9d2-4761-8c0d-081203a4dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(\"timestamp\", \"operation\").toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fa840-98d3-4da4-bcd7-0f68629d3a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().pivot(index='timestamp', columns='operation', values='state').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf94a47-cc80-4f9d-a332-dd8aaa99f01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bbc8f1c-cc1b-4694-9e2b-9468894cdcaf",
   "metadata": {},
   "source": [
    "## Delete some data\n",
    "\n",
    "Delta tables allow deletion of data. We could for example imagine that there is a GDPR-request to delete operation 1.\n",
    "This seems to work, we do not see the operation in the plot neither."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa56d4-5a46-45bf-a5e0-cdcb97f09761",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.delete('operation=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7209ea-bc1f-4fc4-a933-b2d82dacf502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(\"/data/operation-history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340be480-7168-47fd-9c7a-30ec687156c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().pivot(index='timestamp', columns='operation', values='state').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac14f24-5973-426f-844b-4f682f8c48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.history().orderBy(\"version\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5830c-193a-4a38-9a43-479df49897e3",
   "metadata": {},
   "source": [
    "## Vacuum data\n",
    "\n",
    "However when we look into the data folder, we see that the data is still there. \n",
    "Using time travel, we can also reproduce the previous state and see the plot with operation 1.\n",
    "This is useful in case somebody made a mistake!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa6c71-7270-4b4f-8976-1bf9c6f2eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/operation-history/operation=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146608e3-48e1-4509-b805-f38a3354463f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8013f-844b-42d7-bffa-eb3d3e2f01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").option(\"versionAsOf\", 4).load(\"/data/operation-history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6db3a-a680-4599-b395-2fd85b7dfd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().pivot(index='timestamp', columns='operation', values='state').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f39c8e-0ac4-4560-99ad-f09ee3f1a548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd77b98-f826-47a1-9d58-21142364f102",
   "metadata": {},
   "source": [
    "But in case of GDPR-requests, this is still a problem, the data needs to be deleted.\n",
    "There is a vacuum command that cleans the history.\n",
    "By default, the history of >178 hours is deleted.\n",
    "Here, we want to delete all history. For this we have to tweak the spark configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971a247-d2d0-43c9-a3c2-32a8f5d2c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.vacuum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a35dbf-64ed-43f1-a988-208e3864710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f41314-8a87-4a7d-82e3-0de894ccc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.vacuum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb7ab3-52cb-4a01-a9aa-a049231e6f87",
   "metadata": {},
   "source": [
    "Now vacuuming works and as we see below the data is really deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8dd4e2-a328-450c-bd22-cb03d2ffb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/operation-history/operation=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f0b6b-a6e2-4387-806c-32079fdae76e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
